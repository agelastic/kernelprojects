From bee98c64eef8214f07d78e654db5fe147dcfca73 Mon Sep 17 00:00:00 2001
From: Vitaly Osipov <vitaly.osipov@gmail.com>
Date: Mon, 12 May 2014 21:56:36 +1000
Subject: [PATCH] Add syscalls to track slob memory claimed and used

Signed-off-by: Vitaly Osipov <vitaly.osipov@gmail.com>
---
 arch/x86/syscalls/syscall_64.tbl |  2 ++
 include/linux/syscalls.h         |  2 ++
 mm/slob.c                        | 20 ++++++++++++++++++++
 3 files changed, 24 insertions(+)

diff --git a/arch/x86/syscalls/syscall_64.tbl b/arch/x86/syscalls/syscall_64.tbl
index ec255a1..00506fc 100644
--- a/arch/x86/syscalls/syscall_64.tbl
+++ b/arch/x86/syscalls/syscall_64.tbl
@@ -323,6 +323,8 @@
 314	common	sched_setattr		sys_sched_setattr
 315	common	sched_getattr		sys_sched_getattr
 316	common	renameat2		sys_renameat2
+317     common  slob_claimed            sys_slob_claimed
+318     common  slob_used               sys_slob_used
 
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index b0881a0..b577676 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -866,4 +866,6 @@ asmlinkage long sys_process_vm_writev(pid_t pid,
 asmlinkage long sys_kcmp(pid_t pid1, pid_t pid2, int type,
 			 unsigned long idx1, unsigned long idx2);
 asmlinkage long sys_finit_module(int fd, const char __user *uargs, int flags);
+asmlinkage long sys_slob_claimed(void);
+asmlinkage long sys_slob_used(void);
 #endif
diff --git a/mm/slob.c b/mm/slob.c
index 21980e0..7efe66a 100644
--- a/mm/slob.c
+++ b/mm/slob.c
@@ -67,6 +67,7 @@
 #include <linux/rcupdate.h>
 #include <linux/list.h>
 #include <linux/kmemleak.h>
+#include <linux/syscalls.h>
 
 #include <trace/events/kmem.h>
 
@@ -101,6 +102,8 @@ static LIST_HEAD(free_slob_small);
 static LIST_HEAD(free_slob_medium);
 static LIST_HEAD(free_slob_large);
 
+static unsigned int mem_total, mem_used;
+
 /*
  * slob_page_free: true for pages on free_slob_pages list.
  */
@@ -307,6 +310,8 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 		if (prev != slob_list->prev &&
 				slob_list->next != prev->next)
 			list_move_tail(slob_list, prev->next);
+
+		mem_used += size;
 		break;
 	}
 	spin_unlock_irqrestore(&slob_lock, flags);
@@ -316,6 +321,7 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 		b = slob_new_pages(gfp & ~__GFP_ZERO, 0, node);
 		if (!b)
 			return NULL;
+		mem_total += PAGE_SIZE;
 		sp = virt_to_page(b);
 		__SetPageSlab(sp);
 
@@ -327,6 +333,7 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 		set_slob_page_free(sp, slob_list);
 		b = slob_page_alloc(sp, size, align);
 		BUG_ON(!b);
+		mem_used += size;
 		spin_unlock_irqrestore(&slob_lock, flags);
 	}
 	if (unlikely((gfp & __GFP_ZERO) && b))
@@ -362,6 +369,8 @@ static void slob_free(void *block, int size)
 		__ClearPageSlab(sp);
 		page_mapcount_reset(sp);
 		slob_free_pages(b, 0);
+		mem_total -= PAGE_SIZE;
+		mem_used -= size;
 		return;
 	}
 
@@ -416,6 +425,7 @@ static void slob_free(void *block, int size)
 			set_slob(prev, slob_units(prev), b);
 	}
 out:
+	mem_used -= size;
 	spin_unlock_irqrestore(&slob_lock, flags);
 }
 
@@ -642,3 +652,13 @@ void __init kmem_cache_init_late(void)
 {
 	slab_state = FULL;
 }
+
+SYSCALL_DEFINE0(slob_claimed)
+{
+	return mem_total;
+}
+
+SYSCALL_DEFINE0(slob_used)
+{
+	return mem_used;
+}
-- 
1.9.1

